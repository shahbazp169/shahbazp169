# -*- coding: utf-8 -*-
"""CS_ann.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gEFfs9xnvN-oSZb1go3opT7xf7bGoOPr

## Importing initial Libraries
"""

import pandas as pd
import keras
from keras.models import Sequential
from keras.layers import Dense
from sklearn.model_selection import train_test_split
import numpy as np

"""## Loading Dataset"""

data = pd.read_csv('/content/J1 sorted #1.xlsx - Sheet1.csv')
data.head()

data.shape

"""## Normalizing and splitting """

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()

from sklearn.model_selection import train_test_split

X = data.iloc[:,0:-1]
# X = data.drop(['CS(Exp.)'], axis=1)
y = data['CS(Exp.)']
X = scaler.fit_transform(X)

# split X and y into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)

model = Sequential(
    [
    Dense(256, input_dim=9, activation='relu'), # Hidden 1
    Dense(512, activation='relu'), # Hidden 2
    Dense(64, activation='relu'), # Hidden 2
    Dense(1)  # Output
    ]
)

model.compile(loss='mse', optimizer='adam',  metrics=['mape'])
model.summary()

hist = model.fit(X_train, y_train, batch_size=4,epochs=100, validation_split=0.2)

model.evaluate(X_test,y_test)

"""# Plotting loss
## Mean Squared Error
"""

import matplotlib.pyplot as plt
plt.plot(hist.history['loss'])
plt.plot(hist.history['val_loss'])
plt.title('Model loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['loss','Validation loss'])
plt.show()

"""## Mean Absolute Percentage Error"""

plt.plot(hist.history['mape'])
plt.plot(hist.history['val_mape'])
plt.title('Model loss (Mean absolute Percentage Error)')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['mape','Validation mape'])
plt.show()

prediction = model.predict(X_test)

y_test1 = np.array(y_test)
for i in range(1,len(prediction)):
    print(y_test1[i],  " --> ", prediction[i,0])

"""## Testing on User Input"""

input_cols = data.iloc[:,0:-1].columns
temp_list = []
for i in input_cols:
    print("Enter "+i+": " )
    i = float(input())
    temp_list.append(i)

input_list = []
input_list.append(temp_list)

input_list = scaler.fit_transform(input_list)
input_list = np.array(input_list)

model.predict(input_list)



















"""# R2-Score
## Custom DNN
"""

from sklearn.metrics import r2_score as R2
print(R2(y_test, model.predict(X_test)))

"""## Random forest Regressor"""

from sklearn.ensemble import RandomForestRegressor as RFR
model1 = RFR()
model1.fit(X_train,y_train)

print(R2(y_test, model1.predict(X_test)))

"""## SVM regressor"""

from sklearn.svm import SVR
model2 = SVR()
model2.fit(X_train,y_train)
print(R2(y_test, model2.predict(X_test)))

from sklearn.linear_model import LinearRegression as LR
model3 = LR()
model3.fit(X_train,y_train)
print(R2(y_test, model3.predict(X_test)))

from sklearn.ensemble import AdaBoostRegressor as ABR 
model4 = ABR()
model4.fit(X_train,y_train)
print(R2(y_test, model4.predict(X_test)))

"""## Bagging Regressor"""

from sklearn.ensemble import BaggingRegressor as BR
model5 = BR()
model5.fit(X_train,y_train)
print(R2(y_test, model5.predict(X_test)))

from sklearn.ensemble import ExtraTreesRegressor as ETR
model6 = ETR()
model6.fit(X_train,y_train)
print(R2(y_test, model6.predict(X_test)))

"""## Gradient Boosting Regressor"""

from sklearn.ensemble import GradientBoostingRegressor as GBR
model7 = GBR()
model7.fit(X_train,y_train)
print(R2(y_test, model7.predict(X_test)))

from sklearn.tree import DecisionTreeRegressor as DTR
model8 = DTR()
model8.fit(X_train,y_train)
print(R2(y_test, model8.predict(X_test)))